{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "agreed-livestock",
   "metadata": {},
   "source": [
    "### importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "equipped-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "extreme-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_and_sentiment = pd.read_csv('sentiments_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "static-station",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>afinn score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentiment_transformer</th>\n",
       "      <th>sentiment_tansformer_NP</th>\n",
       "      <th>transformer_score</th>\n",
       "      <th>sentiment_textblob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sacrificed everything protect corona patients ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>7</td>\n",
       "      <td>0.991190</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.991190</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alert shall new norms laws movement stricter o...</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.2732</td>\n",
       "      <td>8</td>\n",
       "      <td>0.921373</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.921373</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seven promises need make extra care senior cit...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>27</td>\n",
       "      <td>0.973535</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.973535</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>please move unnecessarily help prevent</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>5</td>\n",
       "      <td>0.988771</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.988771</td>\n",
       "      <td>-0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dear leader nation modi ji suggestion need fol...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6808</td>\n",
       "      <td>26</td>\n",
       "      <td>0.994520</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.994520</td>\n",
       "      <td>-0.133333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  afinn score  sentiment  \\\n",
       "0  sacrificed everything protect corona patients ...          1.0     0.3818   \n",
       "1  alert shall new norms laws movement stricter o...         -3.0    -0.2732   \n",
       "2  seven promises need make extra care senior cit...          1.0     0.5719   \n",
       "3             please move unnecessarily help prevent          2.0     0.6249   \n",
       "4  dear leader nation modi ji suggestion need fol...          3.0     0.6808   \n",
       "\n",
       "   word_count  sentiment_transformer  sentiment_tansformer_NP  \\\n",
       "0           7               0.991190                     -1.0   \n",
       "1           8               0.921373                      1.0   \n",
       "2          27               0.973535                     -1.0   \n",
       "3           5               0.988771                     -1.0   \n",
       "4          26               0.994520                     -1.0   \n",
       "\n",
       "   transformer_score  sentiment_textblob  \n",
       "0          -0.991190            0.000000  \n",
       "1           0.921373            0.136364  \n",
       "2          -0.973535            0.016667  \n",
       "3          -0.988771           -0.400000  \n",
       "4          -0.994520           -0.133333  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_and_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dense-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweets_and_sentiment['text']\n",
    "Y = tweets_and_sentiment['sentiment_textblob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "herbal-victim",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_to_cat(int_):\n",
    "    if int_ == 0:\n",
    "        return 0\n",
    "    if int_ < 0:\n",
    "        return -1\n",
    "    if int_ > 0:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.apply(linear_to_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-morris",
   "metadata": {},
   "source": [
    "### importing libraries for machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "amateur-sunrise",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import RidgeClassifier,LogisticRegression\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import classification_report,f1_score,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "interior-adult",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"Logistic Regression\" : LogisticRegression(solver='newton-cg'),\n",
    "         \"SVC\" : SVC(),\n",
    "         \"Multinomial NB\" : MultinomialNB(), \n",
    "         \"Bernoulli NB\" : BernoulliNB(), \n",
    "         \"Ridge Classifier\" : RidgeClassifier(), \n",
    "         \"AdaBoost\" : AdaBoostClassifier(), \n",
    "         \"Perceptron\" : Perceptron(),\n",
    "         \"Passive-Aggresive\" : PassiveAggressiveClassifier()}\n",
    "#         \"KNN\" : KNeighborsClassifier(),\n",
    "#         'Random forest' : RandomForestClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "empirical-funds",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.feature_extraction.text import TfidfVectorizer'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfid = TfidfVectorizer(max_features=2000, sublinear_tf =  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "sought-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfid.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fewer-editor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((109338, 2000), (109338,))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "stable-denmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "serial-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = {}\n",
    "\n",
    "for i in models.keys():\n",
    "    trained_model[i] = models[i].fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-internet",
   "metadata": {},
   "source": [
    "**----------------------------------------------------------------------------------------------------------------------------------------------------------**\n",
    "\n",
    "**----------------------------------------------------------------------------------------------------------------------------------------------------------**\n",
    "\n",
    "### saving the model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "forward-hybrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "liquid-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = []\n",
    "count=0\n",
    "for i in trained_model.keys():\n",
    "    file_name.append(i+'.sav')\n",
    "    count = count+1\n",
    "#     print(file_name[count-1])\n",
    "#     print(trained_model[i])\n",
    "    joblib.dump(trained_model[i], file_name[count-1])\n",
    "    \n",
    "# print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "verified-capability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Logistic Regression.sav',\n",
       " 'SVC.sav',\n",
       " 'Multinomial NB.sav',\n",
       " 'Bernoulli NB.sav',\n",
       " 'Ridge Classifier.sav',\n",
       " 'AdaBoost.sav',\n",
       " 'Perceptron.sav',\n",
       " 'Passive-Aggresive.sav']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "municipal-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_from_joblib = joblib.load('Logistic Regression.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "touched-johnston",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.903544072253344"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_from_joblib.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-citation",
   "metadata": {},
   "source": [
    "**----------------------------------------------------------------------------------------------------------------------------------------------------------**\n",
    "\n",
    "**----------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "developmental-gardening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Logistic Regression--------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.73      0.81      4408\n",
      "           0       0.85      0.98      0.91      7448\n",
      "           1       0.93      0.90      0.92     10012\n",
      "\n",
      "    accuracy                           0.89     21868\n",
      "   macro avg       0.90      0.87      0.88     21868\n",
      "weighted avg       0.90      0.89      0.89     21868\n",
      "\n",
      "--------------- SVC--------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.74      0.82      4408\n",
      "           0       0.85      0.99      0.92      7448\n",
      "           1       0.94      0.90      0.92     10012\n",
      "\n",
      "    accuracy                           0.90     21868\n",
      "   macro avg       0.90      0.88      0.88     21868\n",
      "weighted avg       0.90      0.90      0.90     21868\n",
      "\n",
      "--------------- Multinomial NB--------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.41      0.56      4408\n",
      "           0       0.84      0.66      0.74      7448\n",
      "           1       0.67      0.94      0.79     10012\n",
      "\n",
      "    accuracy                           0.74     21868\n",
      "   macro avg       0.81      0.67      0.70     21868\n",
      "weighted avg       0.78      0.74      0.73     21868\n",
      "\n",
      "--------------- Bernoulli NB--------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.62      0.64      4408\n",
      "           0       0.83      0.82      0.83      7448\n",
      "           1       0.83      0.85      0.84     10012\n",
      "\n",
      "    accuracy                           0.79     21868\n",
      "   macro avg       0.77      0.77      0.77     21868\n",
      "weighted avg       0.79      0.79      0.79     21868\n",
      "\n",
      "--------------- Ridge Classifier--------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.70      0.78      4408\n",
      "           0       0.84      0.97      0.90      7448\n",
      "           1       0.92      0.89      0.90     10012\n",
      "\n",
      "    accuracy                           0.88     21868\n",
      "   macro avg       0.88      0.86      0.86     21868\n",
      "weighted avg       0.88      0.88      0.88     21868\n",
      "\n",
      "--------------- AdaBoost--------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.43      0.56      4408\n",
      "           0       0.62      0.99      0.76      7448\n",
      "           1       0.92      0.70      0.80     10012\n",
      "\n",
      "    accuracy                           0.74     21868\n",
      "   macro avg       0.79      0.71      0.71     21868\n",
      "weighted avg       0.80      0.74      0.74     21868\n",
      "\n",
      "--------------- Perceptron--------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.69      0.77      4408\n",
      "           0       0.88      0.72      0.79      7448\n",
      "           1       0.77      0.94      0.84     10012\n",
      "\n",
      "    accuracy                           0.81     21868\n",
      "   macro avg       0.84      0.78      0.80     21868\n",
      "weighted avg       0.82      0.81      0.81     21868\n",
      "\n",
      "--------------- Passive-Aggresive--------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.71      0.80      4408\n",
      "           0       0.85      0.96      0.90      7448\n",
      "           1       0.90      0.92      0.91     10012\n",
      "\n",
      "    accuracy                           0.89     21868\n",
      "   macro avg       0.89      0.86      0.87     21868\n",
      "weighted avg       0.89      0.89      0.89     21868\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_predict = {}\n",
    "f1_score_ = {}\n",
    "precision_ = {}\n",
    "\n",
    "for i in trained_model.keys():\n",
    "    model_predict[i] = trained_model[i].predict(x_test)\n",
    "    f1_score_[i] = f1_score(y_test,model_predict[i],average='weighted')\n",
    "    precision_[i] = precision_score(y_test,model_predict[i],average='weighted')\n",
    "    print(f'--------------- {i}--------------')\n",
    "    print(f'{classification_report(y_test,model_predict[i])}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "geological-trainer",
   "metadata": {},
   "source": [
    "model_score_train"
   ]
  },
  {
   "cell_type": "raw",
   "id": "specified-shirt",
   "metadata": {},
   "source": [
    "model_score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "proud-helicopter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.892982128595712,\n",
       " 'SVC': 0.8980213925245182,\n",
       " 'Multinomial NB': 0.7251300126170527,\n",
       " 'Bernoulli NB': 0.7940471116879367,\n",
       " 'Ridge Classifier': 0.8786145193884284,\n",
       " 'AdaBoost': 0.736261332438408,\n",
       " 'Perceptron': 0.8094492213024578,\n",
       " 'Passive-Aggresive': 0.885973954368919}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "explicit-recruitment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.8986290671689652,\n",
       " 'SVC': 0.9033204445698527,\n",
       " 'Multinomial NB': 0.7765671726185259,\n",
       " 'Bernoulli NB': 0.7933830763197323,\n",
       " 'Ridge Classifier': 0.8840584688381206,\n",
       " 'AdaBoost': 0.7991581566653012,\n",
       " 'Perceptron': 0.8234863465662463,\n",
       " 'Passive-Aggresive': 0.8913152343773036}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-series",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "determined-honor",
   "metadata": {},
   "source": [
    "### deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-disabled",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_WORDS = 100000  # Parameter indicating the number of words we'll put in the dictionary\n",
    "VAL_SIZE = 10000  # Size of the validation set\n",
    "NB_START_EPOCHS = 10  # Number of epochs we usually start to train with\n",
    "BATCH_SIZE = 200  # Size of the batches used in the mini-batch gradient descent\n",
    "MAX_LEN = 128  # Maximum number of words in a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "alternate-coordinate",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tweets_and_sentiment.text, tweets_and_sentiment.sentiment_textblob, test_size=0.1, random_state=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dedicated-somerset",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = Tokenizer(num_words=NB_WORDS,\n",
    "filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{\"}~\\t\\n',lower=True, split=\" \")\n",
    "tk.fit_on_texts(X_train)\n",
    "X_train_seq = tk.texts_to_sequences(X_train)\n",
    "X_test_seq = tk.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "peaceful-spanking",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seq_trunc = pad_sequences(X_train_seq, maxlen=MAX_LEN)\n",
    "X_test_seq_trunc = pad_sequences(X_test_seq, maxlen=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "identified-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_emb, X_valid_emb, y_train_emb, y_valid_emb = train_test_split(X_train_seq_trunc, y_train, test_size=0.1, random_state=37)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-jonathan",
   "metadata": {},
   "source": [
    "### deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "institutional-cloud",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_model(model, X_train, y_train, X_valid, y_valid):\n",
    "    model.compile(optimizer='adam'                                    # squared_hinge,hinge\n",
    "                  , loss='squared_hinge'\n",
    "                  , metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train\n",
    "                       , y_train\n",
    "                       , epochs=11\n",
    "                       , batch_size=100\n",
    "                       , validation_data=(X_valid, y_valid)\n",
    "                       )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "junior-letters",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 70, 8)             800000    \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 70, 8)             544       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 70, 8)             0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 560)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 561       \n",
      "=================================================================\n",
      "Total params: 801,105\n",
      "Trainable params: 801,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(NB_WORDS, 8,embeddings_initializer=\"glorot_uniform\", input_length=MAX_LEN))\n",
    "model.add(layers.LSTM(8,activation='tanh',return_sequences=True))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1,activation='tanh'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "objective-omega",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "440/886 [=============>................] - ETA: 28s - loss: 0.9027 - accuracy: 0.0191"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-19e68e1b4447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0memb_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeep_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_emb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_emb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid_emb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid_emb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0memb_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-78-348bdb281cd0>\u001b[0m in \u001b[0;36mdeep_model\u001b[1;34m(model, X_train, y_train, X_valid, y_valid)\u001b[0m\n\u001b[0;32m      8\u001b[0m                        \u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                        \u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                        \u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                        )\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3024\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1961\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "emb_history = deep_model(model, X_train_emb, y_train_emb, X_valid_emb, y_valid_emb)\n",
    "emb_history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "hazardous-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric(history, metric_name):\n",
    "    metric = history.history[metric_name]\n",
    "    val_metric = history.history['val_' + metric_name]\n",
    "\n",
    "    e = range(1, NB_START_EPOCHS + 1)\n",
    "\n",
    "    plt.plot(e, metric, 'bo', label='Train ' + metric_name)\n",
    "    plt.plot(e, val_metric, 'b', label='Validation ' + metric_name)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-russian",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric(emb_history, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-metallic",
   "metadata": {},
   "source": [
    "**converting text into tokens - tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = Tokenizer(num_words=NB_WORDS,\n",
    "               filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{\"}~\\t\\n',lower=True, split=\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-modeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_metric(emb_history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-arrangement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, X_train, y_train, X_test, y_test, epoch_stop):\n",
    "    model.fit(X_train\n",
    "              , y_train\n",
    "              , epochs=epoch_stop\n",
    "              , batch_size=BATCH_SIZE\n",
    "              , verbose=0)\n",
    "    results = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-nudist",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "emb_results = test_model(emb_model, X_train_seq_trunc, y_train, X_test_seq_trunc, y_test, 6)\n",
    "print('/n')\n",
    "print('Test accuracy of word embeddings model: {0:.2f}%'.format(emb_results[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-terry",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
